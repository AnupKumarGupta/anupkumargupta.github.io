<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://localhost:4000//feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.3.1">Jekyll</generator><link href="http://localhost:4000//feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000//" rel="alternate" type="text/html" /><updated>2017-08-09T00:00:43+05:30</updated><id>http://localhost:4000///</id><title type="html">Anup Kumar Gupta</title><author><name>Anup Kumar Gupta</name><email>contact@anupkumargupta.me</email></author><entry><title type="html">Normal Equation</title><link href="http://localhost:4000//blog/Normal-Equation/" rel="alternate" type="text/html" title="Normal Equation" /><published>2017-08-08T00:00:00+05:30</published><updated>2017-08-08T00:00:00+05:30</updated><id>http://localhost:4000//blog/Normal%20Equation</id><content type="html" xml:base="http://localhost:4000//blog/Normal-Equation/">&lt;p&gt;Hi guys. For the last couple of weeks I have been taking an awesome course on &lt;code class=&quot;highlighter-rouge&quot;&gt;Machine Learning&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;** 
I have to change this one
 I was going through the topic &lt;code class=&quot;highlighter-rouge&quot;&gt;Multivariate Linear Regression&lt;/code&gt; where the instructor presented an analytic solution &lt;code class=&quot;highlighter-rouge&quot;&gt;Normal Equation&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The derivation of the equation was not discussed, probably due to it was too mathematical. Blah blah…&lt;/p&gt;

&lt;p&gt;**&lt;/p&gt;

&lt;p&gt;Let’s us assume we are given the &lt;code class=&quot;highlighter-rouge&quot;&gt;hypothesis function&lt;/code&gt; as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_{\theta}(x)=\theta_0x_0+\theta_1x_1+\cdots+\theta_nx_n&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\theta_0 , \theta_1, \cdots \theta_n&lt;/script&gt; are the parameters and  &lt;script type=&quot;math/tex&quot;&gt;x_0 , x_1, \cdots x_n&lt;/script&gt; are the features.&lt;/p&gt;

&lt;p&gt;We aim to minimize our &lt;code class=&quot;highlighter-rouge&quot;&gt;cost function&lt;/code&gt; which is as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta_{0...n})=\frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;x^{(i)}&lt;/script&gt; is the &lt;script type=&quot;math/tex&quot;&gt;i^{th}&lt;/script&gt; sample &lt;script type=&quot;math/tex&quot;&gt;(&lt;/script&gt;from a set of m samples&lt;script type=&quot;math/tex&quot;&gt;)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;y^{(i)}&lt;/script&gt; is the &lt;script type=&quot;math/tex&quot;&gt;i^{th}&lt;/script&gt; expected result.&lt;/p&gt;

&lt;p&gt;Let us consider the parameter vector as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta = \begin{bmatrix} \theta_0\\ \theta_1\\ ...\\ \theta_n \end{bmatrix}&lt;/script&gt;

&lt;p&gt;Now the question arises why a matrix ? We have a system of linear equations here and these equations can easily handled by matrix algebra &lt;script type=&quot;math/tex&quot;&gt;(&lt;/script&gt;or linear algebra&lt;script type=&quot;math/tex&quot;&gt;)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Now we consider our feature vector as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x = \begin{bmatrix} 1\\ x_1\\ ...\\ x_n \end{bmatrix}&lt;/script&gt;

&lt;p&gt;where  &lt;script type=&quot;math/tex&quot;&gt;x_1&lt;/script&gt;,  &lt;script type=&quot;math/tex&quot;&gt;x_2&lt;/script&gt; up to &lt;script type=&quot;math/tex&quot;&gt;x_n&lt;/script&gt; are &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; features. We have considered &lt;script type=&quot;math/tex&quot;&gt;x_0&lt;/script&gt; as &lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; for sake of easy calculations. Now intuitively we can say that, for a single feature vector we can write the &lt;code class=&quot;highlighter-rouge&quot;&gt;hypothesis function&lt;/code&gt; as
&lt;script type=&quot;math/tex&quot;&gt;h_{\theta}(x)=\theta^Tx&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Recall that we have &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;data samples&lt;/code&gt; with us. Let us consider a matrix &lt;script type=&quot;math/tex&quot;&gt;(X)&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; rows, each representing a data sample and &lt;script type=&quot;math/tex&quot;&gt;n+1&lt;/script&gt; columns. Now the &lt;code class=&quot;highlighter-rouge&quot;&gt;hypothesis function&lt;/code&gt; can be re-written as 
&lt;script type=&quot;math/tex&quot;&gt;h_{\theta}(x)=X\theta&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;With this, we can rewrite the &lt;code class=&quot;highlighter-rouge&quot;&gt;least-squares cost function&lt;/code&gt; as following, replacing the sum by matrix multiplication:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta)=\frac{1}{2m}(X\theta-y)^T(X\theta-y)&lt;/script&gt;

&lt;p&gt;Let us get rid of &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{2m}&lt;/script&gt;  term, as it plays no role when the derivative is compared to zero.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta)=(X\theta-y)^T(X\theta-y)&lt;/script&gt;

&lt;p&gt;We now apply the following transpose identity &lt;script type=&quot;math/tex&quot;&gt;(A-B)^T = (A^T-B^T)&lt;/script&gt; and get the following equation.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta)=((X\theta)^T-y^T)(X\theta-y)&lt;/script&gt;

&lt;p&gt;Further solving the equation,we get:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta)=(X\theta)^TX\theta-(X\theta)^Ty-y^T(X\theta)+y^Ty&lt;/script&gt;

&lt;p&gt;Now again applying the following identity &lt;script type=&quot;math/tex&quot;&gt;(A*B)^T = (B^T*A^T)&lt;/script&gt; , we can rewrite the equation as given below.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta)=(\theta^TX^T)X\theta-(X\theta)^Ty-y^T(X\theta)+y^Ty&lt;/script&gt;

&lt;p&gt;Now one can easily show that &lt;script type=&quot;math/tex&quot;&gt;(X\theta)^Ty=y^T(X\theta)&lt;/script&gt; and hence we get our final &lt;code class=&quot;highlighter-rouge&quot;&gt;least-squares cost function&lt;/code&gt; is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta)=\theta^TX^TX\theta-2(X\theta)^Ty+y^Ty&lt;/script&gt;

&lt;p&gt;We know that the above function has a minimum value for the &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; at which  &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial J}{\partial \theta}= 0&lt;/script&gt;&lt;/p&gt;</content><author><name>Anup Kumar Gupta</name><email>contact@anupkumargupta.me</email></author><summary type="html">A step by step guide for solving the problem of Multivariate Linear Regression, using the Normal Equations...</summary></entry><entry><title type="html">HelloWorld Angular</title><link href="http://localhost:4000//blog/Hello-World-Angular/" rel="alternate" type="text/html" title="HelloWorld Angular" /><published>2017-07-15T00:00:00+05:30</published><updated>2017-07-15T00:00:00+05:30</updated><id>http://localhost:4000//blog/Hello%20World%20Angular</id><content type="html" xml:base="http://localhost:4000//blog/Hello-World-Angular/">&lt;h3 id=&quot;prerequisites&quot;&gt;Prerequisites:&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Setting up the Development Environment&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Angular requires node 6.9.x and npm 3.x.x for proper functioning.&lt;/li&gt;
  &lt;li&gt;Check if you have &lt;code class=&quot;highlighter-rouge&quot;&gt;node&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;npm&lt;/code&gt; installed on your system. To do this, run the following commands in a terminal/console window.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For node:
 &lt;code class=&quot;highlighter-rouge&quot;&gt;
 node -v
&lt;/code&gt;
 For npm:
 &lt;code class=&quot;highlighter-rouge&quot;&gt;
 npm -v
&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Install &lt;a href=&quot;https://nodejs.org/en/download/&quot;&gt;Node.js and npm&lt;/a&gt; if they are not already installed on your machine.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install the &lt;a href=&quot;https://cli.angular.io/&quot;&gt;Angular CLI&lt;/a&gt;  globally using &lt;code class=&quot;highlighter-rouge&quot;&gt;npm install -g @angular/cli&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;step-1-creating-a-new-project&quot;&gt;Step 1: Creating a new project&lt;/h3&gt;

&lt;p&gt;Open a terminal window or Node.js command prompt if you are on Windows.&lt;/p&gt;

&lt;p&gt;We create a new project and skeleton application using the command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ng new my-app
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here the &lt;code class=&quot;highlighter-rouge&quot;&gt;ng&lt;/code&gt; is for Angular.
We get a file structure something like this.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/0crAT.jpg&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/0crAT.jpg&quot; alt=&quot;File Structure_1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/zEtsK.jpg&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/zEtsK.jpg&quot; alt=&quot;File Structure_2&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There are lots of files. We need not worry about all of them now.&lt;/p&gt;

&lt;h3 id=&quot;step-2-serving-the-application&quot;&gt;Step 2: Serving the application&lt;/h3&gt;

&lt;p&gt;We launch our application using following command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ng serve
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We may use a flag &lt;code class=&quot;highlighter-rouge&quot;&gt;-open&lt;/code&gt;( or simply &lt;code class=&quot;highlighter-rouge&quot;&gt;-o&lt;/code&gt;) which will automatically open our browser on &lt;code class=&quot;highlighter-rouge&quot;&gt;http://localhost:4200/&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ng serve --open
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Navigate browser to the address &lt;code class=&quot;highlighter-rouge&quot;&gt;http://localhost:4200/&lt;/code&gt;. It looks something like this:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/Ssupw.jpg&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/Ssupw.jpg&quot; alt=&quot;Welcome To App&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-3-editing-our-first-angular-component&quot;&gt;Step 3: Editing our first Angular component&lt;/h3&gt;

&lt;p&gt;The CLI created the default Angular component for us. This is the root component and it is named &lt;code class=&quot;highlighter-rouge&quot;&gt;app-root&lt;/code&gt;. One can find it in &lt;code class=&quot;highlighter-rouge&quot;&gt;./src/app/app.component.ts&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Open the component file and change the title property from &lt;code class=&quot;highlighter-rouge&quot;&gt;Welcome to app!!&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;Hello World&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Original Code : Notice the &lt;code class=&quot;highlighter-rouge&quot;&gt;title = 'app';&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/fVVWw.jpg&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/fVVWw.jpg&quot; alt=&quot;Original Code&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Modified Code : Value of &lt;code class=&quot;highlighter-rouge&quot;&gt;title&lt;/code&gt; is changed.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/ycTba.jpg&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/ycTba.jpg&quot; alt=&quot;Modified Code&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Similarly there is a change in &lt;code class=&quot;highlighter-rouge&quot;&gt;./src/app/app.component.html&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Original HTML&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/gwEFE.jpg&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/gwEFE.jpg&quot; alt=&quot;enter image description here&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Modified HTML&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/Sgpwj.jpg&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/Sgpwj.jpg&quot; alt=&quot;enter image description here&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Notice that the value of &lt;code class=&quot;highlighter-rouge&quot;&gt;title&lt;/code&gt; from the &lt;code class=&quot;highlighter-rouge&quot;&gt;./src/app/app.component.ts&lt;/code&gt; will be displayed. The browser reloads automatically when the changes are done. It looks something like this.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/4MWP9.jpg&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/4MWP9.jpg&quot; alt=&quot;Hello World&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To find more on the topic, visit this link &lt;a href=&quot;https://angular.io/guide/quickstart#whats-next&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>Anup Kumar Gupta</name><email>contact@anupkumargupta.me</email></author><summary type="html">Gives you an insight of the Angular Framework and guides to create your 'HelloWorld' application via Angular..</summary></entry><entry><title type="html">Word2Vector</title><link href="http://localhost:4000//blog/Word2Vec/" rel="alternate" type="text/html" title="Word2Vector" /><published>2017-04-28T00:00:00+05:30</published><updated>2017-04-28T00:00:00+05:30</updated><id>http://localhost:4000//blog/Word2Vec</id><content type="html" xml:base="http://localhost:4000//blog/Word2Vec/">&lt;p&gt;This tutorial covers the skip gram neural network architecture for Word2Vec. We will cover, what are word vectors ? What are different approaches to build a Word2Vec system ? Finally we dive deep and will try to build word2vec, the skip-gram model.&lt;/p&gt;

&lt;p&gt;Let’s begin then…&lt;/p&gt;

&lt;p&gt;Machine learning applications on Natural Language are an extremely important tool in the data scientist’s toolbox. One can implement autocompleter, auto-suggester, spam detector in your spam folder or even a text summarizer. When we are playing around with text data, we come across one of the most important aspect :  &lt;code class=&quot;highlighter-rouge&quot;&gt;text classification&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In text classification, the data scientist tries to develop an algorithm that can figure out what a piece of text says. For example if we are given a word or phrase,the system must be able to figure out whether it is related to  a provided article or not? Or whether a proposed title is appropriate for a given novel or not?&lt;/p&gt;

&lt;p&gt;So how will one tackle the problem of relating a word to an article ? One of the most naive approach is to take the word, simply scan the article and find out the occurrence of the word. But is it failproof?&lt;/p&gt;

&lt;p&gt;I guess no. Lets explore some pitfalls of a naive approach to the classification problem.In many cases traditional text classification can be difficult to scale, because of the order of the vocabulary, which counts in the thousands or tens of thousands. In such a case applying a naive approach may not end up with desired results.&lt;/p&gt;

&lt;p&gt;Let us consider the following example. Suppose we are an article and we have to check whether the article is about cats or not ? If we naively  try to find the word “cat” only, we may end up stating that the article is not at all related to the cats, even if we have words like “kitty” or “kitten” there in the article. Moreover this approach requires a great extent of human intervention.&lt;/p&gt;

&lt;p&gt;One solution to these problem is to move to Word2Vec for the processing of our unstructured text data. Word2Vec is an algorithm that takes every word in our vocabulary and turns it into a unique vector that can be added, subtracted, and manipulated in ways just like a vector in space.&lt;/p&gt;

&lt;p&gt;Once these vectors are generated, they end up displaying very interesting relationships between one another. Since the vectors are mathematical entities, we can perform operations such as adding and subtraction on them. We can get amazing results by creating simple word vector equations such:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;KING - MALE + FEMALE = QUEEN&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Also its worth mentioning that, words with similar meaning tend to have &lt;a href=&quot;https://en.wikipedia.org/wiki/Cosine_similarity&quot;&gt;similar vectors&lt;/a&gt;. 
In words of J.R.Firth&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“You shall know a word by the company	it keeps”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now lets dive down, how to start build up these vectors. At first step we start with something known as &lt;code class=&quot;highlighter-rouge&quot;&gt;one hot encoding vector&lt;/code&gt;. A &lt;code class=&quot;highlighter-rouge&quot;&gt;one hot encoding vector&lt;/code&gt; is a vector with one 1 and other entries as 0s. Let’s learn about it, with a small example. Consider a vocabulary with 4 words, {cat, dog, man, kitty}. Now the one hot encoding vector for each word will be of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;1 X size_of_vocab&lt;/code&gt; which turns out to &lt;code class=&quot;highlighter-rouge&quot;&gt;1 X 4&lt;/code&gt;. The vectors for this vocab will be as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat :   [1 0 0 0 ]
dog :   [0 1 0 0 ]
man :   [0 0 1 0 ]
kitty : [0 0 0 1 ]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;A point worth noting is that no two vectors have 1 at same index. Also it’s clear that till now, there is no natural notion of similarity in a set of one-hot vectors. We aim that somehow, we modify these vectors such that, two words with a similar meaning have similar vectors. We will try to achieve something like this.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat :   [1.0  0.2  0.3  0.9 ]
kitty : [0.9  0.1  0.1  1.0 ]
man :   [0.1  0.3  1.0  0.3 ]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We can now see that there is a sense of similarity between cat and kitty, but at the same time man differs from cat or kitty from a great distance.&lt;/p&gt;

&lt;p&gt;Now the question is, how to create these vectors from &lt;code class=&quot;highlighter-rouge&quot;&gt;one hot encoded vectors&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We have two algorithms to perform this task:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Continuous Bag of Words (CBOW)&lt;/li&gt;
  &lt;li&gt;Skip-grams (SG)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Algorithmically,both of these architectures are similar, except that CBOW predicts center words from context words, while the skip-gram does the inverse and predicts source context-words from the center words.&lt;/p&gt;

&lt;p&gt;For example, if we have the sentence: &lt;em&gt;“The quick brown fox jumps”&lt;/em&gt;, then CBOW tries to predict &lt;em&gt;“brown”&lt;/em&gt; from &lt;em&gt;“the”&lt;/em&gt;, &lt;em&gt;“quick”&lt;/em&gt;, &lt;em&gt;“fox”&lt;/em&gt; and &lt;em&gt;“jumps”&lt;/em&gt;, while Skip-Gram tries to predict &lt;em&gt;“the”&lt;/em&gt;, &lt;em&gt;“quick”&lt;/em&gt;, &lt;em&gt;“fox”&lt;/em&gt; and &lt;em&gt;“jumps”&lt;/em&gt; from &lt;em&gt;“brown”&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Let’s start to build our model using Skip Gram approach.&lt;/p&gt;

&lt;p&gt;We will try to define a model that aims to predict the context words given a center word.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(context\mathbin{\vert} W_t &gt; 0)&lt;/script&gt;

&lt;p&gt;where $ W_t $ is the center word. Our model will have a loss function.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J = 1 - P( W_{-t} \mathbin{\vert} W_t  )&lt;/script&gt;

&lt;p&gt;Where $ W_{-t} $ are all the words except the center word. We try to put almost all words of the corpus as the center word $ W_t $ and perform operations such as to minimize the loss. We keep adjusting the vector representations of words so as to minimize this loss. The basic idea is to have a model that tries to predict from given input, calculates loss and then tries to minimize it. ( &lt;em&gt;Good Boy Model&lt;/em&gt;)&lt;/p&gt;

&lt;h3 id=&quot;word2vec-using-skip-gram-model&quot;&gt;Word2Vec using Skip Gram model&lt;/h3&gt;

&lt;p&gt;For a given word $ \left ( i.e. center word \right ) $ we will try to predict surroundings words in a window of radius $ \left ( say m \right ) $.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;equations-and-figures&quot;&gt;Equations and Figures&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;/*Lets us talk in mathematical equations. Suppose we T words, labeled as t=1,2..T.&lt;/p&gt;

&lt;p&gt;For each word t belonging to T, we will calculate probability of occurrence of surrounding words in a radius of ‘m’.
*/&lt;/p&gt;

&lt;p&gt;We have our objective function something like this,&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;more-is-yet-to-come&quot;&gt;More is yet to come&lt;/h3&gt;

&lt;hr /&gt;</content><author><name>Anup Kumar Gupta</name><email>contact@anupkumargupta.me</email></author><summary type="html">This tutorial covers the skip gram neural network architecture for Word2Vec. We will cover, what are word vectors? What are different approaches to build a Word2Vec system ? Finally we dive deep and will try to build word2vec, the skip-gram model..</summary></entry></feed>
